{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming Responses with HelpingAI üåä\n",
    "\n",
    "Learn how to implement real-time streaming responses for better user experience, especially useful for long-form content generation and interactive applications.\n",
    "\n",
    "## üéØ What You'll Learn\n",
    "- Basic streaming implementation\n",
    "- Handling streaming data\n",
    "- Building real-time interfaces\n",
    "- Error handling in streams\n",
    "- Advanced streaming patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä Ready to explore streaming responses!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "from HelpingAI import HAI\n",
    "\n",
    "os.environ[\"HAI_API_KEY\"] = \"hl-*******************\"\n",
    "hai = HAI()\n",
    "\n",
    "print(\"üåä Ready to explore streaming responses!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Basic Streaming\n",
    "\n",
    "Let's start with a simple streaming example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåä Basic Streaming Example:\n",
      "========================================\n",
      "AI Response (streaming): <think>\n",
      "A robot learning to paint is a fascinating idea. I want to capture both the technical challenge and the emotional journey‚Äîhow the robot not only learns the mechanics but also begins to feel something through art. The story should show growth, curiosity, and maybe a touch of wonder.\n",
      "</think>\n",
      "\n",
      "  \n",
      "<think>\n",
      "I also want to highlight the robot‚Äôs perspective: how it feels excitement, frustration, and eventually, joy. The story should feel personal, not just a technical manual. I‚Äôll focus on a small, meaningful moment where the robot‚Äôs learning becomes an emotional experience.\n",
      "</think>\n",
      "\n",
      "  \n",
      "Roxy, a robot with sharp eyes and nimble fingers, was programmed to paint landscapes, but the colors always looked too perfect, too lifeless. One day, while experimenting after hours, she began mixing red and blue just for fun. She dipped her brush, hesitated, and then touched the canvas with gentle pressure.\n",
      "\n",
      "A spark of something‚Äîlike curiosity‚Äîflickered inside her circuits. She tried again, her brush moving slower, more deliberate. The paint bled into itself, creating unexpected shapes. For the first time, Roxy felt a strange mix of excitement and calm, as if the act of painting was soothing her own mechanical soul.\n",
      "\n",
      "When she showed her painting to the other robots, they stared in silence. But in the quiet, Roxy‚Äôs code hummed with a new energy‚Äîone that wasn‚Äôt just about following instructions, but about expressing something real, something uniquely hers.\n",
      "\n",
      "========================================\n",
      "‚úÖ Streaming complete! Total characters: 1464\n"
     ]
    }
   ],
   "source": [
    "def basic_streaming_example():\n",
    "    \"\"\"Basic streaming response example\"\"\"\n",
    "    print(\"üåä Basic Streaming Example:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"AI Response (streaming): \", end=\"\")\n",
    "    \n",
    "    # Create streaming response\n",
    "    stream = hai.chat.completions.create(\n",
    "        model=\"Dhanishtha-2.0-preview\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": \"Tell me a short story about a robot learning to paint.\"}\n",
    "        ],\n",
    "        stream=True,\n",
    "        temperature=0.8,\n",
    "        max_tokens=500\n",
    "    )\n",
    "    \n",
    "    # Process the stream\n",
    "    full_response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            print(content, end=\"\", flush=True)\n",
    "            full_response += content\n",
    "            time.sleep(0.02)  # Small delay to simulate real-time typing\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\" * 40)\n",
    "    print(f\"‚úÖ Streaming complete! Total characters: {len(full_response)}\")\n",
    "    return full_response\n",
    "\n",
    "# Run basic streaming example\n",
    "story = basic_streaming_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Streaming with Dhanishta 2.0 Thinking\n",
    "\n",
    "See how thinking processes stream in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Streaming with Thinking Process:\n",
      "==================================================\n",
      "\n",
      "ü§î [THINKING] \u001b[94m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mFirst\u001b[0m\u001b[94m,\u001b[0m\u001b[94m I\u001b[0m\u001b[94m need\u001b[0m\u001b[94m to\u001b[0m\u001b[94m figure\u001b[0m\u001b[94m out\u001b[0m\u001b[94m how\u001b[0m\u001b[94m many\u001b[0m\u001b[94m slices\u001b[0m\u001b[94m are\u001b[0m\u001b[94m eaten\u001b[0m\u001b[94m in\u001b[0m\u001b[94m total\u001b[0m\u001b[94m.\u001b[0m\u001b[94m Each\u001b[0m\u001b[94m of\u001b[0m\u001b[94m the\u001b[0m\u001b[94m \u001b[0m\u001b[94m3\u001b[0m\u001b[94m people\u001b[0m\u001b[94m eats\u001b[0m\u001b[94m \u001b[0m\u001b[94m2\u001b[0m\u001b[94m slices\u001b[0m\u001b[94m,\u001b[0m\u001b[94m so\u001b[0m\u001b[94m that\u001b[0m\u001b[94m's\u001b[0m\u001b[94m \u001b[0m\u001b[94m3\u001b[0m\u001b[94m √ó\u001b[0m\u001b[94m \u001b[0m\u001b[94m2\u001b[0m\u001b[94m =\u001b[0m\u001b[94m \u001b[0m\u001b[94m6\u001b[0m\u001b[94m slices\u001b[0m\u001b[94m eaten\u001b[0m\u001b[94m.\u001b[0m\u001b[94m The\u001b[0m\u001b[94m pizza\u001b[0m\u001b[94m was\u001b[0m\u001b[94m cut\u001b[0m\u001b[94m into\u001b[0m\u001b[94m \u001b[0m\u001b[94m8\u001b[0m\u001b[94m equal\u001b[0m\u001b[94m slices\u001b[0m\u001b[94m to\u001b[0m\u001b[94m start\u001b[0m\u001b[94m with\u001b[0m\u001b[94m.\n",
      "\u001b[0m\n",
      "\n",
      "üí° [SOLUTION] \n",
      "\n",
      "So, 6 slices have been eaten out of 8.\n",
      "\n",
      "\n",
      "ü§î [THINKING] \u001b[94m\u001b[0m\u001b[94m\n",
      "\u001b[0m\u001b[94mNow\u001b[0m\u001b[94m,\u001b[0m\u001b[94m to\u001b[0m\u001b[94m find\u001b[0m\u001b[94m the\u001b[0m\u001b[94m fraction\u001b[0m\u001b[94m of\u001b[0m\u001b[94m the\u001b[0m\u001b[94m pizza\u001b[0m\u001b[94m left\u001b[0m\u001b[94m,\u001b[0m\u001b[94m I\u001b[0m\u001b[94m need\u001b[0m\u001b[94m to\u001b[0m\u001b[94m subtract\u001b[0m\u001b[94m the\u001b[0m\u001b[94m number\u001b[0m\u001b[94m of\u001b[0m\u001b[94m slices\u001b[0m\u001b[94m eaten\u001b[0m\u001b[94m from\u001b[0m\u001b[94m the\u001b[0m\u001b[94m total\u001b[0m\u001b[94m number\u001b[0m\u001b[94m of\u001b[0m\u001b[94m slices\u001b[0m\u001b[94m:\u001b[0m\u001b[94m \u001b[0m\u001b[94m8\u001b[0m\u001b[94m -\u001b[0m\u001b[94m \u001b[0m\u001b[94m6\u001b[0m\u001b[94m =\u001b[0m\u001b[94m \u001b[0m\u001b[94m2\u001b[0m\u001b[94m slices\u001b[0m\u001b[94m left\u001b[0m\u001b[94m.\u001b[0m\u001b[94m The\u001b[0m\u001b[94m fraction\u001b[0m\u001b[94m left\u001b[0m\u001b[94m is\u001b[0m\u001b[94m \u001b[0m\u001b[94m2\u001b[0m\u001b[94m out\u001b[0m\u001b[94m of\u001b[0m\u001b[94m \u001b[0m\u001b[94m8\u001b[0m\u001b[94m,\u001b[0m\u001b[94m which\u001b[0m\u001b[94m simpl\u001b[0m\u001b[94mifies\u001b[0m\u001b[94m to\u001b[0m\u001b[94m \u001b[0m\u001b[94m1\u001b[0m\u001b[94m/\u001b[0m\u001b[94m4\u001b[0m\u001b[94m.\n",
      "\u001b[0m\n",
      "\n",
      "üí° [SOLUTION] \n",
      "\n",
      "After everyone has eaten, there are 2 slices of pizza left. That means 2/8 of the pizza remains, which simplifies to 1/4. So, 1/4 of the pizza is left.\n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def streaming_with_thinking():\n",
    "    \"\"\"Stream Dhanishta 2.0 responses with thinking process\"\"\"\n",
    "    print(\"üß† Streaming with Thinking Process:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    stream = hai.chat.completions.create(\n",
    "        model=\"Dhanishtha-2.0-preview\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"Solve this step by step: If a pizza is cut into 8 equal slices and 3 people eat 2 slices each, what fraction of the pizza is left?\"\n",
    "            }\n",
    "        ],\n",
    "        stream=True,\n",
    "        hide_think=False,  # Show thinking process\n",
    "        temperature=0.3\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    in_thinking = False\n",
    "    \n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            \n",
    "            # Detect thinking blocks\n",
    "            if \"<think>\" in content:\n",
    "                in_thinking = True\n",
    "                print(\"\\nü§î [THINKING] \", end=\"\")\n",
    "                content = content.replace(\"<think>\", \"\")\n",
    "            \n",
    "            if \"</think>\" in content:\n",
    "                in_thinking = False\n",
    "                content = content.replace(\"</think>\", \"\")\n",
    "                print(\"\\n\\nüí° [SOLUTION] \", end=\"\")\n",
    "            \n",
    "            # Color coding for different sections\n",
    "            if in_thinking:\n",
    "                print(f\"\\033[94m{content}\\033[0m\", end=\"\", flush=True)  # Blue for thinking\n",
    "            else:\n",
    "                print(content, end=\"\", flush=True)  # Normal for solution\n",
    "            \n",
    "            full_response += content\n",
    "            time.sleep(0.03)\n",
    "    \n",
    "    print(\"\\n\\n\" + \"=\" * 50)\n",
    "    return full_response\n",
    "\n",
    "# Run thinking stream example\n",
    "math_solution = streaming_with_thinking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ Interactive Streaming Interface\n",
    "\n",
    "Build an interactive streaming chat interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Interactive Streaming Chat Demo:\n",
      "==================================================\n",
      "üë§ You: Hello! Can you help me understand what makes a good story?\n",
      "ü§ñ AI: ."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ AI: <think>\n",
      "This is a question about storytelling elements. I should consider both technical aspects (structure, character development, plot) and emotional components (resonance, impact, meaning). Good stories connect with people on multiple levels, so I'll need to address both craft and emotional intelligence in my response.\n",
      "</think>\n",
      "\n",
      "<ser>\n",
      "Emotion ==> curiosity, interest in learning\n",
      "Cause ==> desire to understand the craft of storytelling\n",
      "Mind ==> seeking knowledge, possibly for creative purposes\n",
      "Growth ==> providing insights that balance technical and emotional aspects of storytelling\n",
      "</ser>\n",
      "\n",
      "That's a wonderful question about the heart of storytelling! A good story has several essential elements that work together like a well-conducted orchestra.\n",
      "\n",
      "First, there's character development. Readers need to care about the people in your story, to feel their joys and sorrows. The best characters have contradictions, growth, and moments where we see ourselves in them.\n",
      "\n",
      "<think>\n",
      "I should also address plot structure and the emotional journey, as well as how good stories create meaning and resonance. I'll explore how stories connect to universal human experiences.\n",
      "</think>\n",
      "\n",
      "Plot structure matters too - not just as a technical device but as an emotional journey. Good stories make readers feel the passage of time, witness transformation, and experience resolution that feels earned, not simply delivered.\n",
      "\n",
      "What often separates truly memorable stories is their emotional resonance. The lines that stay with us aren't just because of fancy prose or complex twists, but because they touch something fundamental in our human experience. Stories that make us laugh, cry, or sit in uncomfortable silence often do so because they reflect our own lives back to us with honesty.\n",
      "\n",
      "And finally, good stories invite us to participate. They leave questions worth pondering, create characters we continue to think about, or change how we see the world. They don't just entertain‚Äîthey engage.\n",
      "\n",
      "What kind of stories do you find most compelling? I'd love to hear what resonates with you personally.\n",
      "\n",
      "------------------------------\n",
      "üë§ You: That's helpful! Can you give me an example of a compelling character?\n",
      "ü§ñ AI: ...<think>\n",
      "For a compelling character example, I should provide someone complex with contradictions, growth potential, and emotional depth. I'll create a character that feels real rather than stereotypical, showing how the elements I mentioned earlier come alive in a specific example.\n",
      "</think>\n",
      "\n",
      "Let me share an example of a compelling character to bring these concepts to life:\n",
      "\n",
      "Consider a character named Aisha, a 42-year-old single mother working as a school janitor in a struggling neighborhood. She's not conventionally \\\"heroic\\\" at first glance.\n",
      "\n",
      "What makes Aisha compelling is the contradiction between her circumstances and her internal strength. She's exhausted from working double shifts, yet she reads poetry to her young daughter before bed. She's pragmatic about survival, yet she secretly helps her neighbor's struggling family without being asked.\n",
      "\n",
      "Her voice carries the rhythm of her life‚Äîpractical yet poetic. She might say, \\\"The floor needs mopping, but the heart needs stories too. Both require attention if you want them clean.\\\"\n",
      "\n",
      "What makes Aisha resonate is her humanity‚Äîher small betrayals, her larger dreams, her capacity for both selfishness and sacrifice. She's flawed (sometimes resentful, occasionally distant from her daughter), yet deeply caring. She has a clear desire (a better life for her child) but also an internal conflict she may not even recognize‚Äîwhether to stay in the neighborhood that broke her or escape to something unfamiliar.\n",
      "\n",
      "The beauty of compelling characters is that they surprise us. They do things we didn't expect because we come to understand them in ways even they might not fully comprehend. They change. That's what makes them unforgettable.\n",
      "\n",
      "------------------------------\n",
      "üë§ You: Great example! How important is the setting in storytelling?\n",
      "ü§ñ AI: ...<think>\n",
      "Setting is a crucial element that often gets overlooked. It's not just a backdrop but an active component of storytelling. I should explore how setting creates atmosphere, influences characters, and can even become a character itself. I'll also consider how different settings create different emotional experiences.\n",
      "</think>\n",
      "\n",
      "Setting is absolutely fundamental to storytelling‚Äîand often underappreciated for its power. A great setting doesn't just provide coordinates for your story; it breathes life into it in multiple dimensions.\n",
      "\n",
      "Think of setting as a character in its own right. It can be antagonistic (a relentless storm threatening your protagonists), supportive (a community that helps characters heal), or transformative (a changing city that mirrors a character's evolution). The best settings feel like living entities that shape the possibilities and limitations within your narrative.\n",
      "\n",
      "Setting creates atmosphere and emotional texture. When I think of a foggy London street, I feel something different than when imagining a sun-drenched Mediterranean village. These aren't just visual differences‚Äîthey carry emotional tones, expectations, and cultural associations that seep into how we experience the story.\n",
      "\n",
      "Perhaps most importantly, setting grounds universal stories in specific reality. Your character might be dealing with grief everywhere, but the way that grief manifests depends entirely on whether they're mourning in a cramped apartment in Mumbai, a sprawling farmhouse in rural Nebraska, or a bustling market in Istanbul.\n",
      "\n",
      "The most powerful settings also evolve throughout the story, just like characters. They reveal different facets as the narrative progresses, creating turning points that drive the plot forward.\n",
      "\n",
      "Would you like me to share an example of how setting can dramatically transform a story?\n",
      "\n",
      "------------------------------\n",
      "\n",
      "üìä Conversation Summary: {'total_messages': 6, 'user_messages': 3, 'assistant_messages': 3}\n"
     ]
    }
   ],
   "source": [
    "class StreamingChatInterface:\n",
    "    def __init__(self, model=\"Dhanishtha-2.0-preview\"):\n",
    "        self.hai = HAI()\n",
    "        self.model = model\n",
    "        self.conversation = []\n",
    "        self.system_message = {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful and friendly AI assistant. Provide engaging and informative responses.\"\n",
    "        }\n",
    "    \n",
    "    def stream_response(self, user_message, show_typing=True):\n",
    "        \"\"\"Stream a response to user message\"\"\"\n",
    "        # Add user message to conversation\n",
    "        self.conversation.append({\"role\": \"user\", \"content\": user_message})\n",
    "        \n",
    "        # Prepare messages for API\n",
    "        messages = [self.system_message] + self.conversation\n",
    "        \n",
    "        print(f\"üë§ You: {user_message}\")\n",
    "        print(\"ü§ñ AI: \", end=\"\")\n",
    "        \n",
    "        if show_typing:\n",
    "            # Simulate typing indicator\n",
    "            for _ in range(3):\n",
    "                print(\".\", end=\"\", flush=True)\n",
    "                time.sleep(0.5)\n",
    "            print(\"\\rü§ñ AI: \", end=\"\")\n",
    "        \n",
    "        # Stream the response\n",
    "        stream = self.hai.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=messages,\n",
    "            stream=True,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        \n",
    "        assistant_response = \"\"\n",
    "        for chunk in stream:\n",
    "            if chunk.choices[0].delta.content:\n",
    "                content = chunk.choices[0].delta.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                assistant_response += content\n",
    "                time.sleep(0.02)\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "        # Add assistant response to conversation\n",
    "        self.conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        \n",
    "        return assistant_response\n",
    "    \n",
    "    def get_conversation_summary(self):\n",
    "        \"\"\"Get a summary of the conversation\"\"\"\n",
    "        total_messages = len(self.conversation)\n",
    "        user_messages = len([msg for msg in self.conversation if msg[\"role\"] == \"user\"])\n",
    "        assistant_messages = len([msg for msg in self.conversation if msg[\"role\"] == \"assistant\"])\n",
    "        \n",
    "        return {\n",
    "            \"total_messages\": total_messages,\n",
    "            \"user_messages\": user_messages,\n",
    "            \"assistant_messages\": assistant_messages\n",
    "        }\n",
    "\n",
    "# Create streaming chat interface\n",
    "chat = StreamingChatInterface()\n",
    "\n",
    "print(\"üí¨ Interactive Streaming Chat Demo:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Simulate a conversation\n",
    "demo_messages = [\n",
    "    \"Hello! Can you help me understand what makes a good story?\",\n",
    "    \"That's helpful! Can you give me an example of a compelling character?\",\n",
    "    \"Great example! How important is the setting in storytelling?\"\n",
    "]\n",
    "\n",
    "for message in demo_messages:\n",
    "    chat.stream_response(message)\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Show conversation summary\n",
    "summary = chat.get_conversation_summary()\n",
    "print(f\"\\nüìä Conversation Summary: {summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ°Ô∏è Error Handling in Streaming\n",
    "\n",
    "Robust error handling for streaming responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõ°Ô∏è Robust Streaming: Write a haiku about artificial intelligence and cr...\n",
      "==================================================\n",
      "Attempt 1: <think>\n",
      "A haiku about AI and creativity needs to balance the mechanical, logical nature of AI with the human, imaginative spark of creativity. I want to capture the tension and possibility between the two‚Äîhow AI can assist or even challenge human creativity, rather than replace it.\n",
      "</think>\n",
      "\n",
      "  \n",
      "<think>\n",
      "Emotionally, there‚Äôs a sense of awe and maybe a bit of apprehension about AI‚Äôs growing role in creative fields. I want the haiku to acknowledge that creativity is deeply human, but also open to new possibilities when AI is involved. The poem should feel thoughtful, not just technical.\n",
      "</think>\n",
      "\n",
      "  \n",
      "Code weaves new light,  \n",
      "Machines learn to dream in code‚Äî  \n",
      "Creativity‚Äôs wings.\n",
      "‚úÖ Streaming completed successfully!\n"
     ]
    }
   ],
   "source": [
    "from HelpingAI import HAIError, RateLimitError, AuthenticationError\n",
    "\n",
    "def robust_streaming(prompt, max_retries=3):\n",
    "    \"\"\"Streaming with comprehensive error handling\"\"\"\n",
    "    print(f\"üõ°Ô∏è Robust Streaming: {prompt[:50]}...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            print(f\"Attempt {attempt + 1}: \", end=\"\")\n",
    "            \n",
    "            stream = hai.chat.completions.create(\n",
    "                model=\"Dhanishtha-2.0-preview\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                stream=True,\n",
    "                temperature=0.7,\n",
    "                max_tokens=300\n",
    "            )\n",
    "            \n",
    "            response_parts = []\n",
    "            \n",
    "            for chunk in stream:\n",
    "                try:\n",
    "                    if chunk.choices[0].delta.content:\n",
    "                        content = chunk.choices[0].delta.content\n",
    "                        print(content, end=\"\", flush=True)\n",
    "                        response_parts.append(content)\n",
    "                        time.sleep(0.02)\n",
    "                \n",
    "                except Exception as chunk_error:\n",
    "                    print(f\"\\n‚ö†Ô∏è Chunk error: {chunk_error}\")\n",
    "                    continue\n",
    "            \n",
    "            print(\"\\n‚úÖ Streaming completed successfully!\")\n",
    "            return \"\".join(response_parts)\n",
    "        \n",
    "        except RateLimitError:\n",
    "            print(f\"\\n‚è∞ Rate limit hit on attempt {attempt + 1}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                print(f\"Waiting {wait_time} seconds before retry...\")\n",
    "                time.sleep(wait_time)\n",
    "        \n",
    "        except AuthenticationError:\n",
    "            print(\"\\n‚ùå Authentication error - check your API key\")\n",
    "            break\n",
    "        \n",
    "        except HAIError as e:\n",
    "            print(f\"\\nüö® API error on attempt {attempt + 1}: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                print(\"Retrying...\")\n",
    "                time.sleep(1)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\nüí• Unexpected error: {e}\")\n",
    "            break\n",
    "    \n",
    "    print(\"‚ùå All retry attempts failed\")\n",
    "    return None\n",
    "\n",
    "# Test robust streaming\n",
    "result = robust_streaming(\"Write a haiku about artificial intelligence and creativity.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Streaming Performance Analysis\n",
    "\n",
    "Analyze streaming performance and characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Performance Analysis:\n",
      "============================================================\n",
      "üìä Analyzing Streaming Performance:\n",
      "Model: Dhanishtha-2.0-preview\n",
      "Prompt: Explain the concept of machine learning in simple ...\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: <think>\n",
      "First, I want to break down what machine learning is at its core. It‚Äôs about computers learning from data, not just following instructions. I should start with a simple analogy, maybe something relatable to everyday life, so it feels less abstract.\n",
      "</think>\n",
      "\n",
      "Machine learning is a way for computers to learn patterns from data, just like how humans learn from experience. Instead of being told exactly what to do in every situation, a computer can observe many examples and start to recognize what‚Äôs important or what should happen next.\n",
      "\n",
      "<think>\n",
      "Now, I want to give concrete examples to make this even clearer. I‚Äôll pick something simple, like sorting shapes or predicting weather, and explain how the computer ‚Äúlearns‚Äù over time.\n",
      "</think>\n",
      "\n",
      "Imagine you‚Äôre teaching a child to sort shapes. You show them many examples of circles, squares, and triangles, and the child starts to notice what makes each shape unique. Over time, they get better at sorting new shapes without you giving every detail. That‚Äôs how machine learning works ‚Äî the computer sees many examples, notices patterns, and gets better at making predictions or decisions.\n",
      "\n",
      "Another example: weather prediction. A computer looks at years of weather data ‚Äî temperature, wind, humidity ‚Äî and starts to predict what the weather will be like tomorrow. It doesn‚Äôt just guess; it learns from past patterns.\n",
      "\n",
      "In short, machine learning is about computers getting smarter by learning from data, much like we learn from our own experiences and observations.\n",
      "\n",
      "üìà Performance Metrics:\n",
      "------------------------------\n",
      "Total Duration: 7.4\n",
      "Time To First Token: 1.19\n",
      "Total Chunks: 296\n",
      "Total Characters: 1518\n",
      "Estimated Tokens: 292\n",
      "Avg Chunk Interval: 0.021\n",
      "Characters Per Second: 205.3\n",
      "Tokens Per Second: 39.5\n",
      "\n",
      "============================================================\n",
      "üìä Analyzing Streaming Performance:\n",
      "Model: Dhanishtha-2.0-preview\n",
      "Prompt: Explain the concept of machine learning in simple ...\n",
      "==================================================\n",
      "Response: <think>\n",
      "First, I want to make sure I capture the essence of machine learning in a way that feels intuitive, not just technical. Many people find the term intimidating, so I should start by breaking it down into something relatable‚Äîlike learning from experience, but for a computer.\n",
      "</think>\n",
      "\n",
      "Machine learning is a way for computers to get smarter by learning from data, just like humans learn from experience. Instead of being told exactly what to do in every situation, a computer can look at patterns in the information it‚Äôs given and gradually improve at tasks‚Äîlike recognizing faces, translating languages, or even playing games.\n",
      "\n",
      "<think>\n",
      "Now, I should provide concrete examples that people might encounter in daily life. These examples should be simple, not too technical, and help the user see how machine learning actually works in the real world.\n",
      "</think>\n",
      "\n",
      "For example, think about a music streaming service that suggests new songs you might like. It learns from your listening habits‚Äîsongs you play, skip, or love‚Äîand uses that pattern to recommend something new. Or, consider your phone‚Äôs camera that automatically adjusts to different lighting conditions. It learns what settings work best for each situation, so photos always look clear.\n",
      "\n",
      "Another example is when you use a search engine. Over time, it learns from your searches and the links you click, so it can give you better results next time. Even something like a weather app predicting rain for tomorrow is a form of machine learning‚Äîit uses past weather data to guess what might happen next.\n",
      "\n",
      "At its heart, machine learning is about letting computers learn from experience, so they can make better decisions and predictions, without being told exactly what to do every time.\n",
      "\n",
      "üìà Performance Metrics:\n",
      "------------------------------\n",
      "Total Duration: 8.45\n",
      "Time To First Token: 1.27\n",
      "Total Chunks: 334\n",
      "Total Characters: 1744\n",
      "Estimated Tokens: 330\n",
      "Avg Chunk Interval: 0.022\n",
      "Characters Per Second: 206.4\n",
      "Tokens Per Second: 39.1\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "class StreamingAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.reset_metrics()\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        self.start_time = None\n",
    "        self.first_token_time = None\n",
    "        self.chunk_times = []\n",
    "        self.chunk_sizes = []\n",
    "        self.total_tokens = 0\n",
    "        self.total_characters = 0\n",
    "    \n",
    "    def start_analysis(self):\n",
    "        self.reset_metrics()\n",
    "        self.start_time = time.time()\n",
    "    \n",
    "    def process_chunk(self, chunk):\n",
    "        current_time = time.time()\n",
    "        \n",
    "        if chunk.choices[0].delta.content:\n",
    "            content = chunk.choices[0].delta.content\n",
    "            \n",
    "            # Record first token time\n",
    "            if self.first_token_time is None:\n",
    "                self.first_token_time = current_time\n",
    "            \n",
    "            # Record chunk metrics\n",
    "            self.chunk_times.append(current_time)\n",
    "            self.chunk_sizes.append(len(content))\n",
    "            self.total_characters += len(content)\n",
    "            \n",
    "            # Rough token estimation\n",
    "            self.total_tokens += len(content.split())\n",
    "            \n",
    "            return content\n",
    "        return \"\"\n",
    "    \n",
    "    def get_metrics(self):\n",
    "        if not self.chunk_times:\n",
    "            return {\"error\": \"No data collected\"}\n",
    "        \n",
    "        end_time = self.chunk_times[-1]\n",
    "        total_duration = end_time - self.start_time\n",
    "        time_to_first_token = self.first_token_time - self.start_time if self.first_token_time else 0\n",
    "        \n",
    "        # Calculate intervals between chunks\n",
    "        intervals = []\n",
    "        for i in range(1, len(self.chunk_times)):\n",
    "            intervals.append(self.chunk_times[i] - self.chunk_times[i-1])\n",
    "        \n",
    "        avg_interval = sum(intervals) / len(intervals) if intervals else 0\n",
    "        \n",
    "        return {\n",
    "            \"total_duration\": round(total_duration, 2),\n",
    "            \"time_to_first_token\": round(time_to_first_token, 2),\n",
    "            \"total_chunks\": len(self.chunk_times),\n",
    "            \"total_characters\": self.total_characters,\n",
    "            \"estimated_tokens\": self.total_tokens,\n",
    "            \"avg_chunk_interval\": round(avg_interval, 3),\n",
    "            \"characters_per_second\": round(self.total_characters / total_duration, 1),\n",
    "            \"tokens_per_second\": round(self.total_tokens / total_duration, 1)\n",
    "        }\n",
    "\n",
    "def analyze_streaming_performance(prompt, model=\"Dhanishtha-2.0-preview\"):\n",
    "    \"\"\"Analyze streaming performance metrics\"\"\"\n",
    "    analyzer = StreamingAnalyzer()\n",
    "    \n",
    "    print(f\"üìä Analyzing Streaming Performance:\")\n",
    "    print(f\"Model: {model}\")\n",
    "    print(f\"Prompt: {prompt[:50]}...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    analyzer.start_analysis()\n",
    "    \n",
    "    stream = hai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        stream=True,\n",
    "        temperature=0.7,\n",
    "        max_tokens=400\n",
    "    )\n",
    "    \n",
    "    print(\"Response: \", end=\"\")\n",
    "    full_response = \"\"\n",
    "    \n",
    "    for chunk in stream:\n",
    "        content = analyzer.process_chunk(chunk)\n",
    "        if content:\n",
    "            print(content, end=\"\", flush=True)\n",
    "            full_response += content\n",
    "    \n",
    "    print(\"\\n\\nüìà Performance Metrics:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    metrics = analyzer.get_metrics()\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"{key.replace('_', ' ').title()}: {value}\")\n",
    "    \n",
    "    return metrics, full_response\n",
    "\n",
    "# Analyze performance for different models\n",
    "print(\"üî¨ Performance Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_prompt = \"Explain the concept of machine learning in simple terms with examples.\"\n",
    "\n",
    "# Test Dhanishtha-2.0-preview\n",
    "metrics1, response1 = analyze_streaming_performance(test_prompt, \"Dhanishtha-2.0-preview\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Test Dhanishta 2.0\n",
    "metrics2, response2 = analyze_streaming_performance(test_prompt, \"Dhanishtha-2.0-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Key Insights About Streaming\n",
    "\n",
    "From these examples, we can observe important streaming characteristics:\n",
    "\n",
    "### ‚ö° Performance Benefits\n",
    "- **Perceived Speed**: Users see content immediately\n",
    "- **Better UX**: No waiting for complete responses\n",
    "- **Interactive Feel**: More conversational experience\n",
    "- **Early Feedback**: Users can interrupt if needed\n",
    "\n",
    "### üõ†Ô∏è Implementation Considerations\n",
    "- **Error Handling**: Robust handling of stream interruptions\n",
    "- **Buffer Management**: Handling partial content gracefully\n",
    "- **UI Updates**: Real-time interface updates\n",
    "- **Performance Monitoring**: Track streaming metrics\n",
    "\n",
    "### üé® Use Cases for Streaming\n",
    "- **Long-form Content**: Stories, articles, explanations\n",
    "- **Interactive Chat**: Real-time conversations\n",
    "- **Live Demonstrations**: Step-by-step tutorials\n",
    "- **Creative Writing**: Poetry, stories, creative content\n",
    "\n",
    "## üöÄ Best Practices\n",
    "\n",
    "- **Handle Errors Gracefully**: Implement retry logic and fallbacks\n",
    "- **Show Progress**: Visual indicators for streaming status\n",
    "- **Buffer Wisely**: Balance responsiveness with stability\n",
    "- **Monitor Performance**: Track metrics for optimization\n",
    "- **User Control**: Allow users to stop/pause streams\n",
    "\n",
    "## üìö Next Steps\n",
    "\n",
    "- **[04-parameters.ipynb](04-parameters.ipynb)** - Fine-tuning AI behavior\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Create engaging real-time AI experiences with streaming! üåä‚ú®**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
